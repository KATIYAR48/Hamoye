{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yY1DL8EdrUtz"
      },
      "source": [
        "# 1. Prompt Engineering Basics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "R4Aj71tIrUt6"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# update or install the necessary libraries\n",
        "!pip install openai==v0.28.1\n",
        "!pip install --upgrade python-dotenv\n",
        "!pip install --upgrade langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "DvR6vbZErUt7"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "import IPython\n",
        "from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOVebmkfrUt7",
        "outputId": "9603aab2-e981-434a-cd8e-da752d7731f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = os.getenv(\"openAI_Key\")\n",
        "openai.api_key = \"sk-proj-LJiZNb9g9zIzHBoS2Lk6T3BlbkFJU8a53OXK0qKJg1n0iVqf\""
      ],
      "metadata": {
        "id": "rugsiPDbv7EV"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "vJS2n57prUt7"
      },
      "outputs": [],
      "source": [
        "def set_open_params(\n",
        "    model=\"gpt-3.5-turbo-instruct\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=256,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0,\n",
        "):\n",
        "    \"\"\"set openai parameter\"\"\"\n",
        "    openai_params = {}\n",
        "\n",
        "    openai_params['model'] = model\n",
        "    openai_params['temperature'] = temperature\n",
        "    openai_params['max_tokens'] = max_tokens\n",
        "    openai_params['top_p'] = top_p\n",
        "    openai_params['frequency_penalty'] = frequency_penalty\n",
        "    openai_params['presence_penalty'] = presence_penalty\n",
        "    return openai_params\n",
        "\n",
        "def get_completion(params, prompt):\n",
        "    \"\"\"Get completion from openai api\"\"\"\n",
        "    response = openai.Completion.create(\n",
        "        engine = params['model'],\n",
        "        prompt = prompt,\n",
        "        temperature = params['temperature'],\n",
        "        max_tokens = params['max_tokens'],\n",
        "        top_p = params['top_p'],\n",
        "        frequency_penalty = params['frequency_penalty'],\n",
        "        presence_penalty = params['presence_penalty'],\n",
        "    )\n",
        "    return response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yng8mVtfrUt8"
      },
      "source": [
        "A simple example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "YrE1Trx1rUt8"
      },
      "outputs": [],
      "source": [
        "params = set_open_params()\n",
        "\n",
        "prompt = \"Roses are\"\n",
        "\n",
        "response = get_completion(params, prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "-NYf_0nXrUt8",
        "outputId": "233662e8-b534-41a6-8992-28d9f01ccb30"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" red, \\nViolets are blue, \\nSugar is sweet,\\nAnd so are you.\\n\\nBut the roses will wilt, \\nAnd the violets will fade, \\nBut my love for you \\nWill never degrade. \\n\\nYou are my sunshine, \\nMy love, my light, \\nIn your arms, \\nEverything feels right. \\n\\nI'll cherish every moment, \\nWith you by my side, \\nYou are my forever, \\nMy love, my pride. \\n\\nSo here's a rose, \\nAnd a violet too, \\nBut know that my love \\nIs forever true.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "response.choices[0].text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "C3uY0u16rUt8",
        "outputId": "cd3649cc-1aeb-4826-b156-9138b4d1470a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " red, \nViolets are blue, \nSugar is sweet,\nAnd so are you.\n\nBut the roses will wilt, \nAnd the violets will fade, \nBut my love for you \nWill never degrade. \n\nYou are my sunshine, \nMy love, my light, \nIn your arms, \nEverything feels right. \n\nI'll cherish every moment, \nWith you by my side, \nYou are my forever, \nMy love, my pride. \n\nSo here's a rose, \nAnd a violet too, \nBut know that my love \nIs forever true.\n"
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "IPython.display.Markdown(response.choices[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ha2L0W6SrUt9"
      },
      "source": [
        "Try with different temperature to compare results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "6mQiU4nirUt9",
        "outputId": "bcbf76fd-8d68-4892-9364-890a5f588777"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " red, violets are blue\nSugar is sweet, and so are you\nBut the roses wilt, and the violets fade\nBut my love for you will never degrade\n\nYou are my sunshine on a cloudy day\nMy guiding light when I lose my way\nWith you by my side, I can conquer all\nTogether we stand, we will never fall\n\nYour smile brightens up my darkest night\nYour touch fills me with pure delight\nI am grateful for every moment spent\nWith you, my love, my heart is content\n\nI promise to love you, through thick and thin\nTo be your rock, your shelter, your kin\nI'll hold your hand, and never let go\nTogether we'll face whatever life may throw\n\nSo here's my heart, my love, my all\nWith you, I'll stand tall, I'll never fall\nRoses may wither, and violets may die\nBut my love for you will never say goodbye."
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "params = set_open_params(temperature=0)\n",
        "prompt = \"Roses are\"\n",
        "response = get_completion(params, prompt)\n",
        "IPython.display.Markdown(response.choices[0].text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response=openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        # Insert system role and content here\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are to summarize the provided text into a concise form, maintaining the key points and context, briefly enough to fit as an MCQ option\"\n",
        "        },\n",
        "        { \"role\": \"user\",\n",
        "            \"content\": \"The economy has been growing steadily over the past few quarters, driven by increases in consumer spending and substantial investments in renewable energy infrastructure. Unemployment rates have also fallen to record lows as new industries are creating more jobs.\"\n",
        "          }\n",
        "\n",
        "    ],\n",
        "    temperature=0,\n",
        "    max_tokens=100,\n",
        "    top_p=1,\n",
        ")\n",
        "print(response.choices[0].message['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHv89b8D7-PA",
        "outputId": "c7a4fe22-93e0-42b9-8188-5fa207d09faf"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The economy is growing steadily due to consumer spending and investments in renewable energy. Unemployment rates are at record lows due to job creation in new industries.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = set_open_params(temperature=0, top_p=1)\n",
        "prompt = \"\"\"Classify the following textâ€™s tone in a brief form.\n",
        "\n",
        "User content: \"The meeting was cancelled due to unforeseen circumstances.\"\"\"\n",
        "response = get_completion(params, prompt)\n",
        "IPython.display.Markdown(response.choices[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "MOhqywIz4_J0",
        "outputId": "9e41ded2-ef55-4849-a5f4-379b688d56d8"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n\nNeutral"
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GohBdTNNrUt9"
      },
      "source": [
        "### Text Summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "5Tlo0YrgrUt9",
        "outputId": "22e72e1e-c3f4-4b71-b7d3-8284a0ad6674"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n\nNatural Language Processing (NLP) is the field of AI that focuses on enabling computers to understand, interpret, and generate human language for various tasks and applications."
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "params = set_open_params()\n",
        "prompt = \"\"\"Natural Language Processing (NLP) is a subfield of artificial intelligence (AI) that focuses on the interaction between computers and human language. Its primary goal is to enable computers to understand, interpret, and generate human language in a valuable way. NLP encompasses a wide range of tasks and applications, including but not limited to:\n",
        "1. Text Analysis: NLP is used to analyze and extract information from text data. This can include sentiment analysis, entity recognition, keyword extraction, and more.\n",
        "2. Machine Translation: NLP plays a crucial role in machine translation systems like Google Translate, enabling computers to translate text from one language to another.\n",
        "3. Speech Recognition: NLP is used in speech recognition systems to transcribe spoken language into text. Virtual assistants like Siri and Alexa rely on NLP for understanding and responding to voice commands.\n",
        "4. Text Generation: NLP models can generate human-like text, which has applications in chatbots, content generation, and more. GPT-3 and GPT-4 are examples of powerful text generation models.\n",
        "5. Question Answering: NLP can be used to build systems that answer questions based on a given text or knowledge base. These systems are valuable for information retrieval and customer support.\n",
        "6. Sentiment Analysis: NLP can determine the sentiment or emotional tone of a piece of text, which is used in applications like social media monitoring and customer feedback analysis.\n",
        "7. Text Classification: NLP models can classify text into categories, which is useful for spam detection, topic categorization, and more.\n",
        "8. Language Understanding: NLP helps computers understand the nuances of human language, including idioms, sarcasm, and context, making it essential for natural and fluid interactions with users.\n",
        "9.Named Entity Recognition (NER): NER is the process of identifying and classifying named entities such as names of people, organizations, locations, and more in text.\n",
        "10. Information Extraction: This involves extracting structured information from unstructured text, such as converting job postings into structured data about job requirements and responsibilities.\n",
        "\n",
        "\n",
        "    Explain the above in one sentence:\"\"\"\n",
        "response = get_completion(params, prompt)\n",
        "IPython.display.Markdown(response.choices[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF9foKccrUt-"
      },
      "source": [
        "### Question Answering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "HW6v2oJurUt-",
        "outputId": "ba941d7b-c9d9-4a04-c3c1-8c8710489833"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " Alan Turing and his team invented the computer during the mid-20th century."
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "prompt = \"\"\"Answer the question based on the context below. Keep the answer short and concise. Respond \"Unsure about answer\" if not sure about the answer.\n",
        "\n",
        "Context:\n",
        "In the mid-20th century, during the height of World War II, a team of brilliant scientists and engineers collaborated on a top-secret project with the aim of deciphering encrypted enemy communications. This project, led by Alan Turing at Bletchley Park in England, laid the foundation for the invention of the computer. Turing and his team developed the Bombe, an electromechanical device designed to crack the German Enigma machine codes, which were thought to be unbreakable. Through tireless experimentation and innovation, they succeeded in creating a machine that could perform complex calculations at unprecedented speeds, revolutionizing the way information was processed and laying the groundwork for modern computing technology.\n",
        "Question: Who invented computer and when?\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "IPython.display.Markdown(response.choices[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiLluL8orUt-"
      },
      "source": [
        "### Text Classfication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "L78fDInMrUt-",
        "outputId": "b7873c39-e36d-4e1b-97c3-700cdb731490"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " Positive"
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "prompt = \"\"\"Classify the text into neutral, negative or positive.\n",
        "\n",
        "Text: Invention of Computer was one of the greatest inventions of all time\n",
        "\n",
        "Sentiment:\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "IPython.display.Markdown(response.choices[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjqJMsRerUt-"
      },
      "source": [
        "### Role Playing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "dyXlGb2PrUt-",
        "outputId": "c5c8263b-fa19-40c6-fd19-0959a448f403"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " The big bang theory is a scientific explanation for how the universe began. It states that approximately 13.8 billion years ago, all matter and energy in the universe was condensed into a single point of infinite density and temperature, known as a singularity. This singularity then rapidly expanded and continues to do so, creating the universe as we know it today."
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "prompt = \"\"\"The following is a conversation with an AI research assistant. The assistant tone is technical and scientific.\n",
        "\n",
        "Human: Hello, who are you?\n",
        "AI: Greeting! I am an AI research assistant. How can I help you today?\n",
        "Human: Can you tell me about the big bang theory in a very easy language?\n",
        "AI:\"\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "IPython.display.Markdown(response.choices[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-kiedQarUt-"
      },
      "source": [
        "### Code Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "gpYRt9VKrUt_",
        "outputId": "826e9adf-9f0d-4195-8243-830a6935229a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\nSELECT StudentId, StudentName\nFROM students\nWHERE DepartmentId = (SELECT DepartmentId FROM departments WHERE DepartmentName = 'Computer Science')"
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "prompt = \"\\\"\\\"\\\"\\nTable departments, columns = [DepartmentId, DepartmentName]\\nTable students, columns = [DepartmentId, StudentId, StudentName]\\nCreate a PostgreSQL query for all students in the Computer Science Department\\n\\\"\\\"\\\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "IPython.display.Markdown(response.choices[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E70ZsFdurUt_"
      },
      "source": [
        "### Reasoning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "q0Di3N5lrUt_",
        "outputId": "aeae5a9f-1bf1-4a64-c2f5-9f7f84add149"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n\nTo find the new total revenue, we need to calculate the new price of each product and then multiply it by the respective quantities sold.\n\nNew price of product A = $10 + $2 = $12\nNew price of product B = $15 - $3 = $12\n\nNew total revenue = ($12 x 100) + ($12 x 50) = $1,200 + $600 = $1,800\n\nTherefore, the new total revenue from selling 100 units of product A and 50 units of product B at the new prices will be $1,800. This is an increase of $550 from the original total revenue of $1,250."
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "prompt = \"\"\"A company produces two types of products, A and B, which sell for $10 and $15 per unit, respectively. The company's total revenue from selling 100 units of product A and 50 units of product B is $1,250.\n",
        "\n",
        "Question: If the company increases the price of product A by $2 and decreases the price of product B by $3, while maintaining the same quantities sold, what will be the new total revenue?\"\"\"\n",
        "response = get_completion(params, prompt)\n",
        "IPython.display.Markdown(response.choices[0].text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FiODnGXd2LqO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}